<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[AI行业相关思考]]></title>
    <url>%2Fposts%2Fa889.html</url>
    <content type="text"><![CDATA[现状从现状来看，人工智能技术方面的应用类型笔者认为可以大致分为CV（计算机视觉）、NLP（自然语言处理）、RL（强化学习）、数据挖掘。这几类当中，CV的落地大致在安防、娱乐、生物识别等方面，RL的落地大致在游戏AI、终端设备控制等方面，而NLP与数据挖掘则落地在搜索、推荐、广告、风控等方面。从技术的短期变现能力而言，NLP与数据挖掘的变现能力是最强的。这个原因是CV和RL的技术应用主要还是要凝结在产品中的，这种变现能力基本是要被产品本身的变现能力和市场表现所覆盖，所以商业变现能力较弱。而NLP与数据挖掘的应用则是直接针对数据与流量，它们的应用是可以直接影响市场表现的，所以商业变现能力较强。目前的人工智能基本都是专有人工智能，换句话说，就是“有多少人工，就有多少智能”，然而饭要一口一口吃，我们在通往绚丽的未来之前还是要经历这些人工智障的工作，不积跬步，无以致千里。 如何构建商业AI关于这个问题，业内各有各的提法。不过基本都包含如下几个要素：数据、算法、算力，当然最重要的前提是目标需求明确。首先一个企业是否需要AI，最重要的就是你的目标有没有这方面的需求。如果说一个能用if else写的逻辑非要建模来实现来，这种实在本末倒置，要保证项目不是为了AI而AI，AI永远只是手段而不是目的。 我们再看一下商业AI的其他的几个要素。首先是数据，这个是最重要的，如果无数据，可以根据初始的业务经验和专家规则上线系统，在业务过程中积累数据，再构建模型替代。当然，这里的数据要包含符合业务目标的反馈信息在里面的。对于监督学习，很多人对数据很容易忽略一个监督学习的大前提，即特征与类标之间具有联合概率分布，且训练的数据与后面待测的数据是依联合概率分布独立同分布产生的。在商业应用中，如果忽略数据的大前提，模型的泛化能力无从谈起。其次是算法，这里的算法不是狭义上的统计学习中的算法，而是包含模型，策略与其优化算法的集合。换言之，即对数据的处理方法。在商业应用中，对数据的处理直接关系到产品的效果与市场的表现。最后是算力，即模型训练，评估，上线的物理环境。算力的痛点一般源自实时性要求与功耗要求。 现在的中小企业如要赋能AI或者依托AI来创业，上述要素最难的是需求，其次是数据，然后是算法和算力。所谓需求，即AI在这个产品或者服务中的价值所在。目前的价值基本体现在：精准引导流量，实现核心功能，缩减人力成本，提升用户体验，增加营销噱头。以上几点按变现能力递减排序。接下来最难的便是数据，这里的数据是有价值的数据。做为AI时代的燃料，价值较高的数据基本都为互联网巨头所占有，而众巨头转侧重toB业务来看，这些燃料的消化变现，是需要更多中小企业更个性化的需求和有特色的商业模式的。 后续发展方向思考首先是迁移学习会在企业对投入产出的要求下应用会越来越广泛，并且关于监督学习的AI应用落地会走向模板化，平台化和低门槛化。那么对于从业人员来说，一个比较可能比较残忍的事是在混乱走向有序的大背景下，对从业人员的质量要求会越来越高，跑一个MNIST数据集，做一些竞赛项目就能拿到offer的情况不会再发生了。另外就是深度强化学习这一块技术结合IOT领域会有更有前景，会有很多让人眼前一亮的应用出现。先写到这。]]></content>
      <categories>
        <category>行业思考</category>
      </categories>
      <tags>
        <tag>金融AI</tag>
        <tag>制造业AI</tag>
        <tag>商业模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Otsu算法]]></title>
    <url>%2Fposts%2Fc380.html</url>
    <content type="text"><![CDATA[简介在图像处理中我们经常会遇到（灰度图）二值化的需求，一般情况下可以指定全局阈值进行二值化，那这种时候我们如何知道这个阈值的好坏呢？答案就是不停的尝试。如果是一副双峰图像（双峰图像是指图像直方图中存在两个峰），直观上应该是在两峰之间的峰谷附近取一个值。Otsu就是处理这个问题的，即根据图像直方图自动算出一个阈值。本文会先介绍和简单推导一下公式，然后再脑洞清奇地用代码探索一下Otsu的二值化和kmean的二类聚类方法的效果是否有差异。 原理与公式原理Otsu算法的原理非常简单，算法假定该图像根据双模直方图（前景像素和背景像素）把包含两类像素，于是它要计算能将两类分开的最佳阈值，使得它们的类内方差最小；由于两两平方距离恒定，所以即它们的类间方差最大。 公式推导在大津算法中，我们穷举搜索能使类内方差最小的阈值$t$。类内方差定义为两个类的方差的加权和：$$\sigma_w^2(t) = \omega_1(t)\sigma_1^2(t)+\omega_2(t)\sigma_2^2(t) \tag{1}$$权重 $\omega_i$是被阈值$t$分开的两个类的概率，而 $\sigma^2_ i$是这两个类的类内方差。有：$$\omega_1(t)=\sum_{i=0}^t p(i) \tag{2}$$$$\omega_2(t)=\sum_{i=t+1}^l p(i) \tag{3}$$类均值$\mu_i(t)$为：$$\mu_1(t)=\left[\sum_{i=0}^t p(i)\,x(i)\right]/\omega_1 \tag{4}$$$$\mu_2(t)=\left[\sum_{i=t+1}^l p(i)\,x(i)\right]/\omega_2 \tag{5}$$其中$x(i)$为第$i$个直方图面元中心的值。而类间方差：$$\sigma_b^2(t) = \sigma^2-\sigma_w^2(t)=\omega_1(t)\omega_2(t)[\mu_1(t)-\mu_2(t)]^2 \tag{6}$$可知类间方差最大与类内方差最小等价。 代码我们就采用使得类内方差(1)式最小的方案，Python代码如下1234567891011121314151617181920212223242526import cv2import numpy as npimg = cv2.imread('test.jpg', 0)blur = cv2.GaussianBlur(img, (5, 5), 0)# find normalized_histogram, and its cumulative distribution functionhist = cv2.calcHist([blur], [0], None, [256], [0, 256])hist_norm = hist.ravel()/hist.max()Q = hist_norm.cumsum()bins = np.arange(256)fn_min = np.infthresh = -1for i in range(1, 256): p1, p2 = np.hsplit(hist_norm, [i]) # probabilities q1, q2 = Q[i], Q[255]-Q[i] # cum sum of classes b1, b2 = np.hsplit(bins, [i]) # weights # finding means and variances m1, m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2 v1, v2 = np.sum(((b1-m1)**2)*p1)/q1, np.sum(((b2-m2)**2)*p2)/q2 # calculates the minimization function fn = v1*q1 + v2*q2 if fn &lt; fn_min: fn_min = fn thresh = iprint("loop:", i)print("threshold:", thresh) kmean二值化思考这是笔者的一个脑洞，直接在直方图上做kmean二类聚类，看看是否能够达到和Otsu算法一样的效果。我们先按kmean的思路模拟一下算法流程： 在直方图上任取两个整数点$A_0$,$B_0$，$A_0,B_0\in[0,255]$； 在直方图上的其余点按距离归属为二类，易知$A_i$,$B_i$的中点$M_i$即为分界点，$M_i=(A_i+B_i)/2$； 分别计算被$M_i$分割的两类的加权均值，并用两类的加权均值替换$A_{i+1},B_{i+1}$； 重复第2步和第3步，直到$M_i$变化幅度小于$eps$。 kmean代码12345678910111213141516171819202122232425262728import cv2import numpy as npimg = cv2.imread('test.jpg', 0)blur = cv2.GaussianBlur(img, (5, 5), 0)# find normalized_histogram, and its cumulative distribution functionhist = cv2.calcHist([blur], [0], None, [256], [0, 256])hist_norm = hist.ravel()/hist.max()Q = hist_norm.cumsum()bins = np.arange(256)fn_min = np.infthresh = -1A = 64B = 192eps = 1count = 0for t in range(1, 256): i = int(round((A+B)/2)) p1, p2 = np.hsplit(hist_norm, [i]) # probabilities q1, q2 = Q[i], Q[255]-Q[i] # cum sum of classes b1, b2 = np.hsplit(bins, [i]) # weights # finding means and variances A, B = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2 if abs(((A+B)/2)-i) &lt; eps: count = t breakprint("loop:", count)print("threshold:", i) 结果比较运行上面两段代码如下： Otsu12loop: 255threshold: 120 kmean12loop: 2threshold: 120 从代码上分析也可以看到Otsu法事实上就是遍历直方图的横轴使得类内方差最小即可，迭代次数固定。而kmean方法一般情况下4次左右迭代即可找到与Otsu法一样的结果。 参考大津算法]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>推导</tag>
        <tag>kmean</tag>
        <tag>Otsu</tag>
        <tag>票据识别</tag>
        <tag>二值化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[票据识别的图片前处理]]></title>
    <url>%2Fposts%2F43ea.html</url>
    <content type="text"><![CDATA[问题背景在银行的票据识别的过程中，并非所有的票据都是完整的一张图，有一些票据图片是倾斜并且有背景的，这种在票据识别的版式（也称模板）粗切时，会出现大量的粗切不准现象。所以对这类OCR的票据识别的图片，有必要对其进行规整。 处理算法这里的处理主要还是看图片本身的情况如何，我们接触到的图片，前景为浅色的矩形，大多数是整张票据，但有部分图片中的票据有某几边是存在较深颜色的背景的。并且在深颜色的背景中，还可能会有闪光灯拍照造成的高光区域，颜色基本和票据颜色相近。如果采用普通的找矩形轮廓再透视变换的方法，极可能把大多数整张票据的轮廓进行裁剪，造成处理后的票据图并非整张票据。所以这里需要对此进行特殊处理。下面进行处理算法的详细描述。 二值化图像这里的二值化票据图像的目标就是要把票据的前景显示为白，其他为黑。 首先是把图像转为灰阶图，然后用Otsu算法进行二值化，关于Otsu算法，笔者有一篇专门的文章描述其原理- Otsu算法。在二值化之后，就可以进行形态学闭运算，把票据中的的内容进行清除，减少找轮廓的运算量。这里的闭运算采用的核为10阶。 边缘加边这个想法是整个方案中比较特殊的一个处理。因为如果是已经整张图都是前景票据，这个时候去找轮廓基本上都会影响票据的正常大小。所以这里有一个处理方法是在上述二值化之后的图片的四边均加上一个小边，这个小边的要求是基本上比有深背景的图片的深背景宽度要小。这里取的是20个像素。 寻找轮廓在边缘加边了之后就可以去大胆找轮廓而不用担心轮廓找错，寻找最大的轮廓即可。 多边拟合在找到最大轮廓之后即可对其进行拟合，可以加大类似于tolerance之类的系数让其尽量为一个矩形，从而忽略掉可能会影响轮廓查找的闪光灯高光。 顶点排序顶点排序，即把所有的轮廓点作为输入，找到矩形顶点并进行排序，方便后面透视变换。这里直接把代码打在如下，其中pts为n个二维点的numpy矩阵。 12345678910# 四边形顶点排序，[top-left, top-right, bottom-right, bottom-left]def orderPoints(pts): rect = np.zeros((4, 2), dtype="float32") s = pts.sum(axis=1) rect[0] = pts[np.argmin(s)] rect[2] = pts[np.argmax(s)] diff = np.diff(pts, axis=1) rect[1] = pts[np.argmin(diff)] rect[3] = pts[np.argmax(diff)] return rect 透视变换这个没什么好说的，就是把顶点排序之后的顶点对应到目标顶点直接调接口进行透视变换。目标顶点即为我们需要的分辨率的四个顶点。 遗留问题整个方案的图片处理正确率在98%左右，其他无法处理有如下几类：1.整体亮度都非常暗，2.整体亮度都非常亮或者背景都是浅色背景和前景无法区分者。由于要兼顾效率与效果，目前处理结果已能接受。另外就是在无Opencv的环境还用skimage进行了全套实现。如果有任何问题可以在正文评论提出或者在github的repo中提出。 参考github源码]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>票据识别</tag>
        <tag>OCR</tag>
        <tag>Opencv</tag>
        <tag>Skimage</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测R-CNN系算法]]></title>
    <url>%2Fposts%2F547f.html</url>
    <content type="text"><![CDATA[简介图像分类，检测及分割是计算机视觉领域的三大任务。图像分类模型是将图像划分为单个类别，通常对应于图像中最突出的物体。但是现实世界的很多图片通常包含不只一个物体，此时如果使用图像分类模型为图像分配一个单一标签其实是非常粗糙的，并不准确。对于这样的情况，就需要目标检测模型，目标检测模型可以识别一张图片的多个物体，并可以定位出不同物体（给出边界框）。 目标检测模型的主要性能指标是检测准确度和速度，对于准确度，目标检测还要考虑物体的定位准确性，而不单单是分类准确度。目前主流的目标检测算法主要是基于深度学习模型，其可以分成两大类： two-stage检测算法，其将检测问题划分为两个阶段，首先产生候选区域，然后对候选区域进行校正和分类，这类算法的典型代表是基于候选区域的R-CNN系算法，如R-CNN，Fast R-CNN，Faster R-CNN等； one-stage检测算法，其不需要region proposal阶段，直接产生物体的类别概率和位置坐标值，比较典型的算法如YOLO和SSD。本文是介绍的是第一类two-stage检测算法中的R-CNN系算法——R-CNN，Fast R-CNN，Faster R-CNN，在一般情况下，two-stage算法准确度要优于one-stage检测算法。 R-CNN，即Regions with CNN features，R-CNN是基于候选区域方法的目标检测算法系列开山之作，论文首次将CNN方法引入目标检测领域，大大提高了目标检测效果，也改变了目标检测领域的主要研究思路，之后的Fast R-CNN、Faster R-CNN都是以它为基础。 在R-CNN中，每个候选区域都要单独送入CNN模型计算特征向量，这是非常费时的，为了减少候选区域使用CNN模型提取特征向量所消耗的时间，Fast R-CNN只对整张图像全区域进行一次特征提取，Fast R-CNN最大的贡献是让人们看到了在Region Proposal+CNN这一框架下对目标进行实时检测的希望，也为后来的Faster R-CNN做下了铺垫。 对于Fast R-CNN，其仍然需要selective search方法来生产候选区域，这是非常费时的。为了解决这个问题，Faster R-CNN模型引入了RPN (Region Proposal Network)直接产生候选区域。Faster R-CNN可以看成是RPN和Fast R-CNN模型的组合体。 R-CNN在R-CNN未提出之前，对象检测这一问题基本是遵循着“设计手工特征(Hand-crafted feature)+分类器”的思路，而且由于存在着区域搜索的步骤，所以可以认为是计算机用一个小的矩形窗口不断在图像上滑动、缩放，然后用分类器预测当前滑动窗口所在区域是否存在一个感兴趣的对象。R-CNN利用图片经过CNN模型得到的特征向量代替传统手工计算特征，对目标检测能得到更好的结果。 R-CNN目标检测系统由三个模块组成。 第一个模块生成类别独立候选区域。这些候选区域定义了我们的检测器可用的候选边界框集合。第二个模块是从各个区域提取固定长度特征向量的大型卷积神经网络。 第三个模块是一组类别特定的线性SVM分类器。 对于一张图片，R-CNN基于selective search方法大约生成2000个候选区域，selective search方法是一种启发式搜索算法。它先通过简单的区域划分算法将图片划分成很多小区域，然后通过层级分组方法按照一定相似度合并它们，最后的剩下的就是候选区域，它们可能包含一个物体。生成的每个候选区域被修正成固定大小（227×227）并送入一个CNN模型中，最后得到一个4096维的特征向量。然后这个特征向量被送入一个多类别SVM分类器中，预测出候选区域中所含物体的属于每个类的概率值。每个类别训练一个SVM分类器，从特征向量中推断其属于该类别的概率大小。R-CNN最后又训练了一个边界框回归模型，使用回归模型精细修正候选框位置，提升定位的准确性。 R-CNN网络对比传统的目标识别算法把检测问题转化为了分类问题，采用CNN模型进行特征提取，效果要比传统的手工提取特征方法更好。但R-CNN网络中，一张图经由selective search算法提取约2000个候选区域，每个候选区域都要单独送入CNN模型计算特征向量，这个操作是非常费时的。R-CNN网络训练过程分为提取候选区域、提取CNN特征、SVM分类和Bounding-box 回归等步骤，过于繁琐。R-CNN模型要求输入CNN网络进行提取特征的候选区域是固定尺寸，但其实像AlexNet CNN等网络在提取特征过程中对图像的大小并无要求，只是在提取完特征进行全连接操作的时候才需要固定特征尺寸，这部分也可以进行优化。 Fast R-CNN针对R-CNN网络从候选区域提取特征向量耗时的问题，Fast R-CNN规避了R-CNN中冗余的特征提取操作，只对整张图像全区域进行一次特征提取，用RoI pooling层取代最后一层max pooling层，对于每个候选区域， RoI pooling层可以从CNN特征图中得到一个固定长和宽的特征图（长和宽是超参数，论文中选用的尺寸为7×7），RoI pooling的原理很简单，其根据候选区域按比例从CNN特征图中找到对应的特征区域，然后将其分割成几个子区域（根据要输出的特征图的大小），然后在每个子区域应用max pooling，从而得到固定大小的特征图。Fast R-CNN网络使用SVD对全连接层进行分解，使用了两个不同的全连接层并行操作，可同时输出分类结果和窗口回归结果，减少了计算复杂度，加快检测速度，实现除特征提取阶段外端到端的训练模式，所有的特征都暂存在显存中，不需要额外的磁盘空间。 对Fast R-CNN网络输入一张任意大小的图片，基于selective search方法大约生成2000个候选区域，将图片输入CNN网络，经过若干卷积层与池化层，得到特征图，根据原图中候选区域到特征图映射关系，在特征图中找到每个候选区域对应的特征框，并在RoI池化层中将每个特征框池化到H×W（论文中采用的是7×7）的尺寸，H×W大小的特征框经过全连接层得到固定大小的特征向量，所得到的特征向量再经由SVD分解实现的不同全连接层并行操作，分别得到两个输出向量：一个是softmax的分类得分，一个是Bounding-box窗口回归，利用窗口得分分别对每一类物体进行非极大值抑制剔除重叠的候选区域，最终得到每个类别中回归修正后的得分最高的窗口。 Fast R-CNN相比于R-CNN网络训练速度得到了提高，准确度也略有提升，但其中采用selective search算法提取候选区域，占用了模型大量时间，（selective search算法候选区域提取需要2~3s，而提特征分类只需要0.32s），这还是无法满足目标检测在实时应用中的需求，而且Fast R-CNN网络并没有实现真正意义上的端到端训练模式。 Faster R-CNN这里即为在文本定位算法的文章中用到的算法。 针对Fast R-CNN，使用selective search方法来生产候选区域，非常费时的问题。Faster R-CNN模型引入了区域生成网络RPN (Region Proposal Network)，直接在特征图中提取候选区域，将特征提取，候选区域提取，Bounding-box窗口回归，分类都整合在了一个网络中，实现了端到端的检测模式，虽然训练阶段仍然要分多步，但是检测阶段非常方便快捷。Faster R-CNN可以看成是RPN和Fast R-CNN模型的组合体，RPN的主要思想是通过对应关系把特征图的点映射回原图，在每一个对应的原图设计不同的固定尺度窗口，根据该窗口与真实值的IOU给它正负标签，让它学习里面是否有目标。 对Fast R-CNN网络输入一张任意大小的图片，通过卷积和池化得到特征图。然后在这个特征图上采用一个N×N（文中是3×3）的卷积核，把每个卷积映射位置编码为一个短的（例如256维）特征向量，对于每个位置映射回原图的感受野的中心点当成一个基准点，然后围绕这个基准点选取k个不同大小的候选区域。输出候选区域的分类得分和回归边界。对于分类层，其输出大小是2k，表示各个候选区域包含物体或者是背景的概率值，而回归层输出4k个坐标值，表示各个候选区域的位置。对于每个滑窗位置，这两个全连接层是共享的。RPN采用卷积层来实现：首先是一个n×n卷积得到低维特征，然后是两个1×1的卷积，分别用于分类与回归。 Fast R-CNN抛弃了传统的滑动窗口和基于selective search的方法生成候选区域，直接使用RPN网络，能极大提升候选区域的生成速度，使得利用CNN在线对目标进行识别成为可能。 总结本文介绍了R-CNN, Fast R-CNN, Faster R-CNN三种基于深度学习的目标检测算法。 R-CNN提出了Region Proposal+CNN这一框架，在PASCAL VOC挑战赛上取得了不错的成绩。Fast R-CNN在R-CNN的基础上用RoI pooling层取代最后一层max pooling层，使得输入图片尺寸大小没有限制，并使用SVD分解让分类和窗口回归在全连接层实现并行操作，减少了计算复杂度，加快检测速度。Faster R-CNN在Fast R-CNN的基础上引入RPN，将特征提取，候选区域提取，窗口回归，分类都整合在了一个网络中，真正意义上的实现了端到端的检测模式，进一步加快了模型的检测速度。 参考链接 基于候选区域的深度学习目标检测算法R-CNN，Fast R-CNN，Faster R-CNN]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>神经网络</tag>
        <tag>目标检测</tag>
        <tag>R-CNN</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本定位算法]]></title>
    <url>%2Fposts%2Fad64.html</url>
    <content type="text"><![CDATA[简介⽂本定位主要适⽤于识别图⽚中⽂本的位置信息。利⽤计算机视觉智能识别图⽚中的⽂本信息并进⾏定位，⽣成的带有类别信息的⽬标候选框，经常应⽤于带有多种⽂本信息的票据，证件识别中。本文主要介绍如下两种文本定位算法： Deeptext CTPN DeeptextDeeptext算法原理DeepText是基于Faster R-CNN针对⽂本定位进⾏改进的Two-Stage模型。DeepText的结构和Faster R-CNN如出⼀辙：⾸先特征层使⽤的是VGG-16，其次算法均由⽤于提取候选区域的RPN和⽤于物体检测的Fast R-CNN。关于上述几个结构与概念，有相关卷积神经网络结构和本博客相关文章如下，建议在看本文之前先行阅览： VGG ILSVRC 16 layers 目标检测R-CNN系算法 DeepText的创新点 Inception-RPN：与传统RPN相⽐，使⽤3x3的max pooling, 3x3的卷积以及5x5的卷积，使得在RPN模块可以考虑多尺度的特征； ATC： ⽂本与其他物体检测不同的是很多置信度在[0.2,0.5]的框内也是有⽂本存在的（物体检测⼀般将置信度⼩于0.5的样例当作负样例），这样就会将很多⽂本当作负样例，影响最终的结果。所以DeepText在RCNN的分类结果中加⼊了ATC的分类（正、ATC、负）; MLRP：在Detection Network模块中使⽤来⾃不同卷积层的特征，因为不同层的特征不同，融合多种特征可以提升指标； IBBV：使⽤多个Iteration的bounding boxes的集合使⽤NMS； Scales：针对⽂本特征修改超参数，⽀持(2,3,4,5)四种scale； Ratios：针对⽂本特征修改超参数， ⽀持(0.2, 0.5, 0.8, 1.0, 1.2, 1.5)六种scale； DeepText的⽹络结构 指标介绍验证指标⽂本定位验证指标主要是计算预测出来的物体的位置的框与真实的框之间的精确率（precision）,召回率（recall）, F值（F-Measure），相关的定义如下： 精确率：预测为某类样本（例如正样本）中有多少是真正的该类样本。 召回率：样本中的某类样本有多少被正确预测了。 F值：P和R指标有时候会出现的⽭盾的情况，这样就需要综合考虑他们，F-Measure是Precision和Recall加权调和平均。 训练指标 训练总损失： ⽂本定位的验证指标主要是训练损失，代表了真实值和预测值之间的差值，如果训练损失越来越⼩，代表模型预测的能⼒越来越强。 训练准确率： 训练准确率则代表着训练集上被预测准确的样本数占总样本的⽐例情况； CTPN算法概述CTPN是基于Faster-RCNN针对⽂本定位进⾏改进的Two-Stage模型。 CTPN的结构如Faster R-CNN如出⼀辙：⾸先特征层使⽤的是VGG-16，其次算法均由⽤于提取候选区域的RPN和⽤于物体检测的Fast R-CNN。DeepText的创新点如下： BLSTM：CTPN结构与Faster R-CNN基本类似，但是加⼊了LSTM层。该循环⽹络层采⽤双向LSTM，使得⽹络学习到了⽂字前向、后向的序列信息，但是训练过程需要⼩⼼梯度爆炸。 定宽的anchor： 由于CTPN针对的是横向排列的⽂字检测，所以其采⽤了⼀组（10个）等宽度的Anchors，⽤于定位⽂字位置。Anchor宽⾼为：width = [16] ,height = [11,16,23,33,48,68,97,139,198,283];该设置⽅法保证了在x⽅向上，Anchor覆盖原图每个点且不相互重叠，并且anchor⾼度覆盖了不同尺度⽂本⽬标。 ⽂本线构造：在获得多个text proposal的基础上，需要将各个group的proposal进⾏合并，即将定宽proposal链接成标准框，主要利⽤计算overlap以及⽔平正向距离确group，再执⾏框链接算法； 指标介绍验证指标⽂本定位验证指标主要是计算预测出来的物体的位置的框与真实的框之间的精确率（precision）,召回率（recall）, F值（F-Measure），相关的定义如下： Precision：预测为某类样本（例如正样本）中有多少是真正的该类样本。 Recall：样本中的某类样本有多少被正确预测了。 F-Measure：P和R指标有时候会出现的⽭盾的情况，这样就需要综合考虑他们，F-Measure是Precision和Recall加权调和平均。 训练指标⽂本定位的验证指标主要是训练损失，代表了真实值和预测值之间的差值，如果训练损失越来越⼩，代表模型预测的能⼒越来越好。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>OCR</tag>
        <tag>Deeptext</tag>
        <tag>CTPN</tag>
        <tag>CV</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提升树原理与推导]]></title>
    <url>%2Fposts%2Fe647.html</url>
    <content type="text"><![CDATA[简介本文主要讲提升树的模型与算法，并会在最后对梯度提升树进行比较与描述。在看XGBoost原理与推导前，可先看本文，对提升树有一个基本了解。 提升树模型我们先来看一下提升树的模型，提升方法实际采用的仍然是加法模型(即基函数的线性组合)和前向分步算法。当基函数是决策树的时候，这个提升方法就叫提升树。根据上述，我们可以把提升树的模型公式表示出来：$$f_M(x)=\sum_{m=1}^MT(x;\Theta_m) \tag{1}$$其中，$T(x;\Theta_m)$就表示决策树。$x$为输入的样本。$\Theta_m$为第$m$棵树的参数，从回归树原理与推导中来看，类似其叶子节点权重。$M$为树的总棵树。 提升树算法提升树算法也是用前向分步算法，我们设第$m$步的模型是$$f_m(x)=f_{m-1}(x)+T(x;\Theta_m) \tag{2}$$也就是说模型是在之前训练好的结果上加上当前的决策树的输出。 对于第$m$步的最优参数$\hat{\Theta}_m$，根据经验风险最小化的策略，有：$$\hat{\Theta}m=\arg \min{\Theta_m}\sum_{i=1}^N\mathcal{L}(y_i,f_m(x_i)) \tag{3}$$我们假定采用平方误差损失，即有：$$\mathcal{L}(y,f_m(x))=(y-f_m(x))^2 \tag{4}$$我们把(2)式代入(4)式，有：$$\mathcal{L}(y,f_{m-1}(x)+T(x;\Theta_m))=(y-f_{m-1}(x)-T(x;\Theta_m))^2 \tag{5}$$我们令$$r=y-f_{m-1}(x) \tag{6}$$则(5)式可以写成：$$\mathcal{L}(y,f_{m-1}(x)+T(x;\Theta_m))=(r-T(x;\Theta_m))^2 \tag{7}$$我们把$r$叫作当前模型拟合数据的残差(residual)，从(7)式可以看到，要使损失变小，即要让当前的树的输出拟合当前模型的残差。如何去拟合呢？可以参考回归树原理与推导。 梯度提升树对于上述提升树，我们做了一个假设为损失为平方误差损失，如果推及一般损失函数，每一步的优化并不简单了。针对这个问题，Freidman提出了梯度提升的算法，即利用损失函数的负梯度在当前模型的值来近似(6)式中的残差(如果损失为平方误差损失，那么负梯度就是残差)。即$$r_{mi}=-[\frac{\partial \mathcal{L(y_i,f(x_i))}}{\partial f(x_i)}]{f(x)=f{m-1}(x)} \tag{8}$$其中$i$为样本数，$m$为提升迭代第$m$轮。与我们比较熟悉的梯度下降的算法思想类似。 参考文献 《统计学习方法》李航 8.4 Greedy function approximation: a gradient boosting machine]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>推导</tag>
        <tag>GBDT</tag>
        <tag>提升树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回归树原理与推导]]></title>
    <url>%2Fposts%2F917e.html</url>
    <content type="text"><![CDATA[CART简介本文主要讲回归树和最小二乘回归树的算法，目的是对决策树做回归有一个认识，并且熟悉经典的最小二乘回归树。我们这里只关注CART的回归树，CART(classification and regressioin tree)是在给定输入随机变量$X$条件下输出 随机变量$Y$的条件概率分布的学习方法。CART假设决策树是二叉树，内部结点特征的取值为“是”和“否”。其中的回归决策树等价于递归地二分每个特征，将输入空间即特征空间切分为有限个单元，并在这些单元上确定预测的回归值。当切分完毕，这些单元就是回归树上的叶子节点，这些单元上的预测值，就是叶子节点的取值。 怎么做从上述简介可以看出生成一个回归树大致需要两部，第一步，切分特征空间为有限个单元；第二步，在每个切分后的单元上确定代表该单元的回归值。下面先讲如何确定单元取值，再讲如何切分特征空间。 确定单元取值假设$X$与$Y$分别为输入和输出变量，并且$Y$是连续变量，给定训练数据集：$$D={(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)}$$其中$x \in R^d$，一个回归树对应着输入空间（即特征空间）的一个切分和在切分后的单元上的输出值。我们这里假设输入空间已经被切分为$M$个单元$R_1,R_2,\dots,R_M$，并且每个单元有一个固定的输出值$c_m$，那么回归树的模型就可以写成：$$f(x)=\sum_{m=1}^Mc_mI(x \in R_m) \tag{1}$$那么如何确定每个$R_m$上的取值呢？我们这里的最小二乘回归树用平方误差来表示回归树的单元取值与真实值的误差，即：$$\mathcal{L}=\sum_{x_i \in R_m}(y_i-f(x_i))^2 \tag{2}$$根据最小二乘法，可以很容易知道单元$R_m$上的$c_m$的最优值$\hat{c}_m$是$R_m$的所有样本的输出$y_i$的均值，即：$$\hat{c}_m=\frac{1}{N_m}\sum_{x_i\in R_m(j,s)}y_i \tag{3}$$其中$N_m$为落在切分空间$R_m$的所有样本数目，$R_m(j,s)$意思是切分变量$x^{(j)}$(即输入变量的第$j$维特征)和对应的切分点$s$对应的切后单元空间。到这里就解决了问题：假设切分空间确定后，每个空间所代表的值。 切分特征空间那么回归树的问题就剩余如何确定输入空间的切分。事实上只要找到切分变量$x^{(j)}$(即输入变量的第$j$维特征)和对应的切分点$s$，然后再针对切分后的子空间递归进行切分直到满足建树停止条件即可。 这里定义切分后的两个区域为$R_1$和$R_2$，有：$$R_1(j,s)={x|x^{(j)}\leq s}$$$$R_2(j,s)={x|x^{(j)}&gt; s}$$然后求解如下式寻找最优切分变量$j$和最优切分点$s$：$$min_{j,s}[min_{c_1}\sum_{x_i\in R_1(j,s)}(y_i-c_1)^2 + min_{c_2}\sum_{x_i\in R_2(j,s)}(y_i-c_2)^2] \tag{4}$$解释一下(4)式，即选取输入变量$x$的第$j$维，并扫描切分点$s$，当切分的两个子单元的方差之和最小，则为第$j$维的最优切分点。遍历所有找到符合(4)式的$j,s$，切分为两个子单元，再对子单元按(4)式进行递归切分直到满足停止条件即可。 这里找切分点的方法思想本质还是最小二乘法，与图像二值化当中的Otsu算法有点神似。 参考文献《统计学习方法》李航 5.5.1]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>推导</tag>
        <tag>最小二乘回归树</tag>
        <tag>回归树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XGBoost原理与推导]]></title>
    <url>%2Fposts%2F933a.html</url>
    <content type="text"><![CDATA[简介 本文不讲如何使用XGBoost也不讲如何调参，主要会讲一下作为GBDT中的一种，XGBoost的原理与相关公式推导。为了循序渐进的理解，读者可先从简单的回归树再到提升树再来看本文。关于回归树与提升树占位链接如下。我们现在直接从XGBoost的目标函数讲起。 回归树原理与推导 提升树原理与推导 XGBoost公式推导 XGBoost的目标函数如下： \[ obj=\sum_{i=1}^n\mathcal{L}(y_i,\hat{y}_i)+\sum \Omega(f_k),f_k\in\mathcal{F} \tag1\] 上面的两项加号前项为在训练集上的损失函数。其中\(y_i\)表示真实值，\(\hat{y}_i\)表示预测值。加号后项为正则项，到后面再看\(\Omega\)这个函数的具体形式。我们现在只需要知道\(\Omega\)的自变量为\(f_k\)，是决策树，而不是向量，所以是没有办法用和导数有关的方法来训练的（像梯度下降等）。 Boosting 何为Boosting，这个可以主要在上面给的提升树文章中去了解。这里大概描述如下： \[\hat{y}_i^{(0)}=0\] \[\hat{y}_i^{(1)}=f_1(x_i)=\hat{y}_i^{(0)}+f_1(x_i)\] \[\hat{y}_i^{(2)}=f_1(x_i)+f_2(x_i)=\hat{y}_i^{(1)}+f_2(x_i)\] 依此类推，每次迭代轮数均比上次迭代好一些，通式如下： \[\hat{y}_i^{(t)}=\sum_{k=1}^tf_k(x_i)=\hat{y}_i^{(t-1)}+f_t(x_i) \tag2\] 上面(2)式即为对于第t轮的boosting公式。我们再看此时的目标函数： \[ obj^{(t)}=\sum_{i=1}^n\mathcal{L}(y_i,\hat{y}_i^{(t)})+\sum_{i=1}^t \Omega(f_k) \tag3\] 其中(3)式\(n\)为样本数，\(t\)为树的棵数，也是迭代的轮数，\(y_i\)为真实值，\(\hat{y}_i\)为第\(t\)轮的预测值 。对于正则化项，又可以写成如下形式： \[ \sum_{i=1}^t \Omega(f_k)=\Omega(f_t)+ \sum_{i=1}^{t-1} \Omega(f_k)\tag4\] (4)式这么写有什么好处呢？因为我们的方法是boosting逐轮计算的，所以当计算第\(t\)轮时，前面\(t-1\)轮事实上是已经计算出来了的。即(4)式的加号后项为常数。所以把(2)(4)式代入(3)式，有如下： \[ obj^{(t)}=\sum_{i=1}^n\mathcal{L}(y_i,\hat{y}_i^{(t-1)}+f_t(x_i))+\Omega(f_t)+const \tag5\] Taylor展开 在(5)这个式子的基础上，我们就可以做点文章了。我们现在假定经验损失\(\mathcal{L}\)是可以二阶Taylor展开的。把\(f_t(x_i)\)当成无穷小，就得到了如下式： \[ obj^{(t)}\approx\sum_{i=1}^n[\mathcal{L}(y_i,\hat{y}_i^{(t-1)})+g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t)+const \tag6\] (6)这个式子是比较抽象的，为帮助对\(g_i\)和\(h_i\)的理解，我们把常见的平方损失函数代入(5)可有： \[ obj^{(t)}=\sum_{i=1}^n(y_i-(\hat{y}_i^{(t-1)}+f_t(x_i)))^2+\Omega(f_t)+const\] 展开有： \[ obj^{(t)}=\sum_{i=1}^n[(y_i-\hat{y}_i^{(t-1)})^2+2(\hat{y}_i^{(t-1)}-y_i)f_t(x_i)+f_t^2(x_i)]+\Omega(f_t)+const\] 即： \[ obj^{(t)}=\sum_{i=1}^n[\mathcal{L}(y_i,\hat{y}^{(t-1)})+2(\hat{y}_i^{(t-1)}-y_i)f_t(x_i)+f_t^2(x_i)]+\Omega(f_t)+const\] 套用一下(6)式，即有当损失函数为平方损失时\(g_i=2(\hat{y}_i^{(t-1)}-y_i)\)，\(h_i=2\)。 我们再考察(6)式，其中的\(\mathcal{L}(y_i,\hat{y}_i^{(t-1)})\)意义是\(t-1\)轮的经验损失，在执行第\(t\)轮的时候，这一项其实已经也是一个已知的常数。那么优化目标就可以继续简化如下： \[ obj^{(t)}=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t) \tag7\] 其中，\(g_i\)和\(h_i\)可根据Taylor公式求得如下： \[\begin{cases} g_i=\partial_{\hat{y}^{(t-1)}}\mathcal{L}(y_i,\hat{y}^{(t-1)})\\ h_i=\partial^2_{\hat{y}^{(t-1)}}\mathcal{L}(y_i,\hat{y}^{(t-1)})\\ \end{cases} \tag8\] 也就是说在给定损失函数的形式，则\(g_i\)和\(h_i\)就可以算出来。 树的权重求解与结构分 我们从(7)式再往下，把\(f_t(x)\)搞清楚。有： \[f_t(x)=w_{q(x)},w\in R^T,q:R^d\to \{1,2,\cdots,T\} \tag9\] \(f_t(x)\)表示第\(t\)棵树，\(x\)为输入特征，其维数为\(d\)，\(f_t(x)\)即为把特征映射到一个树的叶子结点上的一个数（权重），\(f_t(x)\)可以分为\(w\)和\(q\)两部分，其中\(q\)为把特征映射到一个\(T\)个叶子结点的函数，相当于是决策树的结构。\(w\)为把每个叶子结点映射为其权重值。 树的函数搞清了，如果没有搞清楚，可以从本文开头提到的回归树原理与推导和提升树原理与推导再深入学习一下。 我们考察(7)式中的罚项\(\Omega(f_t)\)，这个罚项是用来惩罚树的复杂程度的。根据上面\(f_t(x)\)的描述，我们可以从树的结构与树叶子结点上的权重做罚项，我们定义如下： \[\Omega(f_t)=\gamma T+\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2 \tag{10}\] 其中\(T\)为叶子节点个数，\(w\)为叶子节点权重。我们把(10)式加号前项叫L0范数，加号后项为L2范数，\(\gamma\)和\(\lambda\)分别为各自超参数。 我们把(10)式，(9)式都代入(7)式，有： \[ obj^{(t)}=\sum_{i=1}^n[g_iw_{q(x_i)}+\frac{1}{2}h_iw^2_{q(x_i)}]+\gamma T+\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2 \tag{11}\] 到这里，我们可以看到(7)式中优化事实上可以着重分为两大步，第一步拿到树结构，第二步再计算叶子节点上的权重大小。我们先令： \[I_j=\{i|q(x_i)=j\},j\in \{1,2,\cdots,T\} \tag{12}\] (12)式的意思是定义所有落在第\(j\)个叶子节点的样本为\(I_j\)，即被映射到第\(j\)个叶子节点上的所有样本\(x_i\)的索引。那么对(11)式按树的叶子节点分组重写如下： \[ obj^{(t)}=\sum_{j=1}^T[(\sum_{i\in I_j}g_i)w_j+\frac{1}{2}(\sum_{i\in I_j}h_i+\lambda)w^2_j]+\gamma T\tag{13}\] 我们令 \[G_j=\sum_{i\in I_j}g_i \tag{14}\] \[H_j=\sum_{i\in I_j}h_i \tag{15}\] 把(14)(15)代入(13)有： \[ obj^{(t)}=\sum_{j=1}^T[G_jw_j+\frac{1}{2}(H_j+\lambda)w^2_j]+\gamma T\tag{16}\] 我们假定这时候树的结构已经知道，那么映射到叶子节点\(j\)上面的样本索引就固定了，而损失函数也是已知的，由(8)可有\(g_i\)和\(h_i\)都是已知的，进而\(G_j\)和\(H_j\)则都是已知的。那么，目标函数就变成了求叶子节点个数\(T\)个的关于\(w\)的一元二次函数求和的形式，而且他们两两之间都是独立的。接下来我们对每个\(w\)进行求解，用到的就是高中数学知识了。对于每个这个形式的一元二次函数，可有取极值时的\(w\)： \[argmin_w[Gw+\frac{1}{2}(H+\lambda)w^2]=-\frac{G}{H+\lambda},H&gt;0 \tag{17}\] 这个时候极值为: \[min_w[Gw+\frac{1}{2}(H+\lambda)w^2]=-\frac{G^2}{2(H+\lambda)} \tag{18}\] 即这个时候，目标函数的极值： \[\hat{obj}^{(t)}=-\sum_{j=1}^T\frac{G^2}{2(H+\lambda)}+\gamma T \tag{19}\] 也被称为树的结构分。 到这里，我们解决了一个问题，就是在知道每轮的树的结构\(q\)的前提下，我们能够很快求得每个叶子节点上的最优权重值\(w\)。 如何找到最优的树结构 那么如何获取最优的树结构呢？方式一：遍历所有可能的树结构，计算每种可能的树的结构分，然后再找到最小结构分对应的权重。这种方式可想而知根本无法实际应用。方式二：基于贪心策略，每次分裂都使得分裂后的增益最大。这种方式其实与决策树的树基本生成算法类似，只是增益的定义不一样。我们这里的增益可以用树的结构分来定义，每次树的分裂点使得整体树的结构分下降得最大，定义如下： \[\mathcal{L}_{split}=\frac{1}{2}(\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L^2+G_R^2)}{H_L+H_R+\lambda})-\gamma \tag{20}\] 总结 我们对本文从上到下总结一下。XGBoost首先确定好树的棵数。对于每轮的那棵树，其形成步骤大体可以分为两大块，第一要先确定好树的最优结构，一般会根据树的结构分下降最大的分裂点进行贪心算法构造，当然这里会有一些单棵树的深度或者叶子节点数限制。当树的结构确定好之后，对于每个叶子节点的权重，可以很快地用一元二次函数解法求得。当此轮的树生成完毕后，即可求得每个样本的预测结果，从而进行下一轮迭代。 参考文献 XGBoost: A Scalable Tree Boosting System]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>推导</tag>
        <tag>GBDT</tag>
        <tag>XGBoost</tag>
        <tag>boosting</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logistic Regression原理与推导]]></title>
    <url>%2Fposts%2Fd28f.html</url>
    <content type="text"><![CDATA[简介 本文不讲如何使用逻辑回归，主要会讲一下逻辑回归的算法和模型背后的假设。主要分为两部分，一个是逻辑回归公式的推导，其次会讲述一下如何理解sigmoid函数。 逻辑回归推导 首先我们知道逻辑回归的一个sigmoid假设，这个假设背后的由来我们会在后面给出，请先记得这个假设。公式如下： \[ p(y=1|x) = \frac {1} {1+e^{-(\theta^Tx+b)}} \tag1\] 这个假设告诉我们分为正样本的概率为(1)中右式。其中\(x\)为输入的向量，计算的结果与0.5比较，如果大于0.5则为正样本。右式的值域易知为(0,1)。对于负样本，有： \[ p(y=0|x) = 1-p(y=1|x) \tag2\] 综合上述二式可得： \[ p(y|x) = p(y=1|x)^yp(y=0|x)^{1-y} \tag3\] 注意得到上式用到了数学的trick，即下式： $$ \[\begin{cases} p(y=1|x),y=1\\ p(x=0|x),y=0\\ \end{cases}\] $$ 我们继续往下。事实上，从(3)式我们就知道了概率函数\(p(y|x)\)，拿到概率函数，我们可以求其最大似然估计（maximum likelihood estimation，MLE）。 MLE是用来估计概率模型的参数的一种方法，最大似然估计会寻找关于 \(\theta\) 的最可能的值（即，在所有可能的\(\theta\) 取值中，寻找一个值使这个采样的“可能性”最大化）。从数学上来说，我们可以在\(\theta\)的所有可能取值中寻找一个值使得似然函数取到最大值。这个使可能性最大的\(\widehat{\theta}\)值即称为 \(\theta\)的最大似然估计。由定义，最大似然估计是样本的函数。 如果有n个样本，那么其似然函数为(3)式的n个样本的乘积： \[ likelihood=\prod_{i=1}^np(y_i|x_i) \tag4\] \[ likelihood=\prod_{i=1}^np(y_i=1|x_i)^{y_i}p(y_i=0|x_i)^{1-y_i} \tag5\] 对(5)取log： \[ log\_likelihood=\sum_{i=1}^ny_i*ln(p(y_i=1|x_i))+(1-y_i)*ln(p(y_i=0|x_i)) \tag6\] 于是就变成了对数似然函数(6)，对log_likelihood，我们是希望它越大越好（极大似然估计），如果对其取负，则可以作为损失函数，我们是希望损失越小越好。这里的优化方法，先从简单的说，可用梯度下降进行迭代优化（对数似然函数对应地用梯度上升）。 我们现在把最初始的(1)式代入(6)： \[ log\_likelihood=\sum_{i=1}^ny_i*ln(\frac {1} {1+e^{-(\theta^Tx_i+b)}})+(1-y_i)*ln(1-\frac {1} {1+e^{-(\theta^Tx_i+b)}}) \tag7\] 对于sigmoid函数，求导是非常方便的。即有： \[ f(x)=\frac1{1+e^{-x}} \tag8\] \[ f^\prime(x)=f(x)*(1-f(x)) \tag9\] 那么(7)式对\(\theta\)求梯度有： \[ \nabla_\theta log\_likelihood=\sum_{i=1}^n x_i*(y_i-\frac{1}{1+e^{-(\theta^T x_i+b)}}) \tag{10}\] 其中(10)式中的b可以先忽略（可以与\(\theta\)统一）。 迭代优化方式 BGD(Batch Gradient Descent) 对极大似然函数梯度上升，有： \[ \vec\theta_{i+1}= \vec\theta_{i}+\lambda*\nabla_\theta log\_likelihood \tag{11}\] 把(10)代入，即： \[ \vec\theta_{i+1}= \vec\theta_{i}+\lambda*\sum_{i=1}^n \vec x_i*(y_i-\frac{1}{1+e^{-(\vec\theta^T \vec x_i+b)}}) \tag{12}\] (12)式就是全批量梯度更新方法，其中\(\lambda\)即为一般意义上的学习步长。从(12)式可以看到，要把n个数据样本全部代入后方可进行梯度更新。计算来说是比较繁琐的。而根据监督学习的假设样本数据是依据某种联合概率分布独立同分布产生，那么可有一种一次用一个样本的梯度更新方式，就是SGD(Stochastic Gradient Descent)。 SGD(Stochastic Gradient Descent) 随机梯度更新方式就是在(12)式去掉了求和符号： \[ \vec\theta_{i+1}= \vec\theta_{i}+\lambda*\vec x_i*(y_i-\frac{1}{1+e^{-(\vec\theta^T \vec x_i+b)}}) \tag{13}\] 随机梯度更新方式来一条样本即可做一次更新，通常情况下会引入较大的随机性。BGD和SGD很明显都比较极端，那么就有了一种折中方式Mini-Batch GD Mini-Batch GD(Mini-Batch Gradient Descent) 与BGD类似，只是所有样本的计算换成部分样本计算： \[ \vec\theta_{i+1}= \vec\theta_{i}+\lambda*\sum_{i=1}^m \vec x_i*(y_i-\frac{1}{1+e^{-(\vec\theta^T \vec x_i+b)}}) \tag{14}\] 其中\(m\ll n\)，这样做的好处就是可以综合SGD和BGD。在较快更新速度的同时可以有一定的随机性防止陷入局部最优。以上的梯度更新方式在神经网络的训练中也可以借鉴。 sigmoid函数的由来 我们在最开始有一个假设，一切的出发点为(1)中的假设。那么为什么会有这样一个假设呢？ 我们先看一个一般性的二分类的贝叶斯公式，二类分别为C1和C2： \[ p(C1|x)=\frac{p(x|C1)p(C1)}{p(x|C1)p(C1)+p(x|C2)p(C2)} \tag{15}\] 我们对(15)式右边的分子分母同时除以\(p(x|C1)p(C1)\)（二分类问题可保证其一定不为0），那么就有： \[ p(C1|x)=\frac1{1+\frac{p(x|C2)p(C2)}{p(x|C1)p(C1)}} \tag{16}\] 我们可以令： \[a=ln\frac{p(x|C1)p(C1)}{p(x|C2)p(C2)} \tag{17}\] 那么把(17)代入(16)，即有： \[ p(C1|x)=\frac1{1+e^{-a}} \tag{18}\] 上面的(18)式就是我们最初的sigmoid函数。我们再看一下(17)式，用人话把\(ln\)的对象描述如下：分类为C1的x出现的概率比上分类为C2的x出现的概率。 广义指数分布函数族 虽然(18)式看着和我们最开始的假设很像，但细心的读者可以看到最开始假设的\(a\)是\(\theta\)和\(x\)的线性函数。而(17)式目前看不出来像。 我们先看一下广义指数分布函数族的概念，对于广义指数分布函数族，有： \[ p(x|\lambda_k)=h(x)g(\lambda_k)e^{\lambda_k^Tu(x)} \tag{19}\] 把(19)代入(17)，有： \[a=ln\frac{h(x)g(\lambda_1)e^{\lambda_1^Tu(x)}p(C1)}{h(x)g(\lambda_2)e^{\lambda_2^Tu(x)}p(C2)} \tag{20}\] \(h(x)\)可以约掉，\(g(\lambda_i)\)是常数项可有： \[a=(\lambda_1-\lambda_2)^Tu(x)+ln(\frac{g(\lambda_1)}{g(\lambda_2)})+ln(\frac{p(C1)}{p(C2)}) \tag{21}\] 即： \[a=(\lambda_1-\lambda_2)^Tu(x)+const \tag{22}\] 上面就告诉我们，当\(p(x|C1)\)和\(p(x|C2)\)满足广义指数分布，并且是其中一种特例（\(u(x)=x\)），就可以满足\(a\)是\(\theta\)和\(x\)的线性函数，其中\((\lambda_1-\lambda_2)=\theta\)。 其他广义指数分布函数 这里给出结论，感兴趣者可作详细推导：满足\(a\)是\(\theta\)和\(x\)的线性函数的广义指数分布还有如下： Gaussian分布 Binomial分布 Poisson分布 Bernoulli分布 可以看到逻辑回归的适用范围是比较广的。 参考链接 最大似然估计 Exponential family]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>LR</tag>
        <tag>逻辑回归</tag>
        <tag>logistic regression</tag>
        <tag>SGD</tag>
        <tag>BGD</tag>
        <tag>梯度下降</tag>
        <tag>原理</tag>
        <tag>推导</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[parquet转csv]]></title>
    <url>%2Fposts%2Fcd96.html</url>
    <content type="text"><![CDATA[parquet是什么Apache Parquet 是一种 列式存储 格式可用于 Hadoop 生态系统中的任何组件，无论是数据处理框架，数据模型，或者编程语言。Parquet 文件格式包含几个支持数据仓库风格操作的功能 : 列式存储设计 - 仅仅从数据文件或者表中读取一小部分数据时查询可以检测和执行计算所有值中的一个列。 灵活的压缩选项 - 数据能够使用几种编码器压缩。可以将不同的数据文件压缩成不同的格式。 新颖的编码方案 - 相同的，相似的或者相关数据值的序列可以存储在硬盘和内存。The encoding schemes provide an extra level of space savings beyond overall compression for each data file。 大的文件 - Parquet 数据文件是被设计用于优化查询大量数据，单个文件大小在 MB 甚至 GB 以上。 在实际的数据挖掘工作中，可能会有把parquet文件转为csv后本地验证或者实验的需求。 如何把parquet转为csv前期准备需要安装pyarrow库：1conda install pyarrow or1pip install pyarrow 处理转换python文件如下：1234567891011121314151617181920212223242526272829303132333435363738import osimport pandas as pdimport pyarrow.parquet as pqdef read_pyarrow(path, use_threads=1): return pq.read_table(path, use_threads=use_threads).to_pandas()def get_file_list(file_dir='.'): L = [] for root, _, files in os.walk(file_dir): for file in files: if os.path.splitext(file)[1] == '.parquet': L.append(os.path.join(root, file)) return Ldef get_csv(file_list): init_flag = 0 for f in file_list: print('The current handling file is:\n', f) if init_flag == 0: init_df = read_pyarrow(f) init_flag = 1 else: t_df = read_pyarrow(f) init_df = pd.concat([init_df, t_df]) return init_dfpath = 'JoinPredict-20190401055632-SLOT_0-29358'file_list = get_file_list(path)df = get_csv(file_list)df.to_csv('./parquet_data.csv', sep=',', index=False, mode='w', line_terminator='\n', encoding='utf-8') 笔者本身的需求便是要把一个文件夹内的多个parquet文件转换为一个总的csv文件。如需要分别转换，修改源码即可。 githubgithub源码 参考链接Parquet 文件]]></content>
      <categories>
        <category>工具环境</category>
      </categories>
      <tags>
        <tag>parquet2csv</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[airflow使用]]></title>
    <url>%2Fposts%2F6a60.html</url>
    <content type="text"><![CDATA[Airflow基本概念Airflow中的相关概念如下： Operators：Airflow定义的一系列算子/操作符，更直接的理解就是python class。不同的Operator类实现了具体的功能，比如： BashOperator：可以执行用户指定的一个Bash命令 PythonOperator：可以执行用户指定的一个python函数 EmailOperator：可以进行邮件发送 Sensor：感知器/触发器，可以定义触发条件和动作，在条件满足时执行某个动作。Airflow提供了更具体的Sensor，比如FileSensor，DatabaseSensor等 DAG(Directed Acyclic Graph): 字面意有向无环图。是执行任务流的图，在此集合中可以定义任务的依赖关系，另外这个DAG是由python实现，存放在$AIRFLOW_HOME路径下的dags文件夹下，可以看成是一个对象，在使用时需要进行实例化。DAG中包含task。 task：任务，Operators的具体实例。 使用步骤 根据实际需要，使用不同的Operator 传入具体的参数，定义一系列的Tasks 定义Tasks间的关系，形成一个DAG 调度DAG运行，每个Task会行成一个Instance 使用命令行或者Web UI进行查看和管理 DAG代码示例下面是一个官方的DAG的python文件示例，为了方便理解，笔者加入了中文注释：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455"""Code that goes along with the Airflow tutorial located at:https://github.com/apache/airflow/blob/master/airflow/example_dags/tutorial.py"""from airflow import DAGfrom airflow.operators.bash_operator import BashOperatorfrom datetime import datetime, timedelta# 以下为DAG的默认参数，这些参数会传给每个operatordefault_args = &#123; 'owner': 'airflow', # 任务的owner,建议用unix user的用户名 'depends_on_past': False, # 当设置为True时，任务实例将按顺序运行，同时依赖于前一个任务的调度成功 'start_date': datetime(2019, 4, 1), # 'email': ['airflow@example.com'], 'email_on_failure': False, 'email_on_retry': False, 'retries': 1, # 在任务报失败前应执行的重试次数 'retry_delay': timedelta(minutes=5), # 重试间的延时 # 'queue': 'bash_queue', # 'pool': 'backfill', # 'priority_weight': 10, # 'end_date': datetime(2016, 1, 1),&#125;# 传参建立dag，其中'luke_airflow'即为dag_id，是dag的唯一标识，schedule_interval为执行频率dag = DAG('luke_airflow', default_args=default_args, schedule_interval=timedelta(days=1))# t1, t2 and t3 are examples of tasks created by instantiating operatorst1 = BashOperator( task_id='print_date', # task_id，任务的唯一标识 bash_command='date', # 执行的bash命令 dag=dag)t2 = BashOperator( task_id='sleep', bash_command='sleep 5', retries=3, dag=dag)templated_command = """ &#123;% for i in range(5) %&#125; echo "&#123;&#123; ds &#125;&#125;" echo "&#123;&#123; macros.ds_add(ds, 7)&#125;&#125;" echo "&#123;&#123; params.my_param &#125;&#125;" &#123;% endfor %&#125;"""t3 = BashOperator( task_id='templated', bash_command=templated_command, params=&#123;'my_param': 'Parameter I passed in'&#125;, dag=dag)t2.set_upstream(t1) # 设置t1为t2的前置任务，参数中可以为task的列表。t3.set_upstream(t1) # 设置t1为t3的前置任务 上面这个文件实质是一个配置文件(像未实例化的对象)，这个脚本不能用于不同文件之间通信，如果要交叉通信，需要用Xcom 另外在task中的传参有如下优先级： BashOperator指定的参数； 如果没有，则用传入的default_args； 如果依然没有，则用Operator的默认参数。 测试解析脚本把上述的文件放到和airflow.cfg同目录下的dags文件夹下，执行。1python3 luke_airflow.py 确保没有报错。 验证脚本让我们运行一些命令来进一步验证这个脚本。12345678# 打印所有激活的dag列表，可以看到luke_airflow的dag在其中airflow list_dags# 打印指定id的dag中任务，这里为"luke_airflow"，可以看到dag中的任务airflow list_tasks luke_airflow# 打印dag中任务树，可以看到dag中任务层级图。airflow list_tasks luke_airflow --tree 执行测试1airflow test luke_airflow templated 2019-03-03 后面跟的日期为模拟执行日期，可以看到执行结果。 其他以上一些操作也可在建立的airflow 网站上用webUI进行操作。 参考链接 airflow 官网 使用 Airflow 替代你的 crontab Apache Airflow]]></content>
      <categories>
        <category>工程实现</category>
      </categories>
      <tags>
        <tag>airflow</tag>
        <tag>ETL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WSL自定义安装路径]]></title>
    <url>%2Fposts%2Fbb32.html</url>
    <content type="text"><![CDATA[WSL是什么Windows Subsystem for Linux（简称WSL）是一个为在Windows 10上能够原生运行Linux二进制可执行文件（ELF格式）的兼容层。它是由微软与Canonical公司合作开发，目标是使纯正的Ubuntu映像能下载和解压到用户的本地计算机，并且映像内的工具和实用工具能在此子系统上原生运行。 在windows 10专业版上面可以使用。可以免去虚拟机安装的麻烦。 WSL有什么问题一个很麻烦的问题是WSL默认在windows商店里面安装，默认安装到系统盘，且后续的根文件系统均在系统盘中，对于系统盘资源较紧张者比较麻烦。 如何解决针对于以上问题，有如下步骤解决: 下载wsl离线安装包wsl离线安装包下载 在Downloading distros中找到要下载的版本下载.Appx文件。 安装LxRunOfflineLxRunOffline下载 解压放在程序路径，并在系统环境变量中添加： 在cmd中有LxRunOffline命令对应提示即为成功。 用LxRunOffline安装wsl离线安装包首先在powershell中输入 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 来打开Linux子系统功能，也可以在控制面板的启用或关闭windows功能勾选打开。 然后使用LxRunOffline 1LxRunOffline i -n &lt;安装名称&gt; -d &lt;安装路径&gt; -f &lt;安装文件&gt; 其中安装名称可以自定义，安装路径为自定义安装路径，安装文件为上一步解压后的文件中的install.tar.gz的路径，回车后等待安装完成。示例如下： 备注若系统中安装不止一个WSL,则可以通过LxRunOffline sd -n &lt;安装名称&gt;设置默认启动系统，然后在cmd中输入wsl启动系统。若忘记安装名称，可通过LxRunOffline list命令查看。 参考链接 百度百科WSL介绍 自定义安装路径安装WSL]]></content>
      <categories>
        <category>工具环境</category>
      </categories>
      <tags>
        <tag>WSL</tag>
        <tag>Linux</tag>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[airflow 从入门到放弃]]></title>
    <url>%2Fposts%2F8439.html</url>
    <content type="text"><![CDATA[airflow是什么Airflow 被 Airbnb 内部用来创建、监控和调整数据管道。任何工作流都可以在这个使用 Python 编写的平台上运行（目前加入 Apache 基金会孵化器）。 Airflow 允许工作流开发人员轻松创建、维护和周期性地调度运行工作流（即有向无环图或成为DAGs）的工具。在Airbnb中，这些工作流包括了如数据存储、增长分析、Email发送、A/B测试等等这些跨越多部门的用例。这个平台拥有和 Hive、Presto、MySQL、HDFS、Postgres和S3交互的能力，并且提供了钩子使得系统拥有很好地扩展性。除了一个命令行界面，该工具还提供了一个 基于Web的用户界面让您可以可视化管道的依赖关系、监控进度、触发任务等。 在ETL(Extract-Transform-Load)中会经常使用脚本（bash/python）+ crontab来运行数据处理任务，然而这种方案存在以下问题 查看任务执行情况不直观方便，只能登录机器、或者写一个界面/监控 存在依赖关系的任务没办法保证，或者保证的方法成本太高 任务量达到一定量级，任务的管理将极其棘手 而airflow有如下优点： Airbnb开源的工作流管理平台 工作流依赖关系的可视化 日志追踪 用Python编写，易于扩展 开箱即用的ETL调度管理平台 运维/作业管理平台 调度平台设计 在一个机器学习建模的工程项目中，数据的ETL处理非常需要airflow。 airflow怎么得到安装airflow原则上不需要多说，但实际操作的过程中出现一些问题。笔者在windows 10的ubuntu 子系统上用python3安装airflow，最开始就出现了如下问题：1234567891011121314pip3 install apache-airflowCollecting apache-airflow Using cached https://files.pythonhosted.org/packages/e4/06/45fe64a358ae595ac562640ce96a320313ff098eeff88afb3ca8293cb6b9/apache-airflow-1.10.2.tar.gz Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "/tmp/pip-build-465wd_ew/apache-airflow/setup.py", line 429, in &lt;module&gt; do_setup() File "/tmp/pip-build-465wd_ew/apache-airflow/setup.py", line 287, in do_setup verify_gpl_dependency() File "/tmp/pip-build-465wd_ew/apache-airflow/setup.py", line 53, in verify_gpl_dependency raise RuntimeError("By default one of Airflow's dependencies installs a GPL " RuntimeError: By default one of Airflow's dependencies installs a GPL dependency (unidecode). To avoid this dependency set SLUGIFY_USES_TEXT_UNIDECODE=yes in your environment when you install or upgrade Airflow. To force installing the GPL version set AIRFLOW_GPL_UNIDECODE 我们可以看到后面给出相关的解决方法，设置SLUGIFY_USES_TEXT_UNIDECODE=yes，如下：1export SLUGIFY_USES_TEXT_UNIDECODE=yes 再次用pip3 install apache-airflow安装，成功！按照官方步骤执行：123export AIRFLOW_HOME=~/airflowairflow initdbairflow webserver -p 8080 在浏览器地址栏输入http://localhost:8080，得下图： 整个airflow的安装在细节上还会有比较多的小问题，要细心排查。上面如果安装后找不到airflow的命令，则找到airflow的脚本所在路径，加入系统PATH即可。实际项目中路径可能会不一样，需要灵活处理。airflow的使用相关的内容请点击airflow使用 参考链接 airflow github 开源中国airflow首页 记一次自认为成功的技术选型——AIRFLOW]]></content>
      <categories>
        <category>工程实现</category>
      </categories>
      <tags>
        <tag>airflow</tag>
        <tag>ETL</tag>
      </tags>
  </entry>
</search>
